{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bariscemb/saatUygulamas-/blob/main/GCN_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the required packages and preprocessed Elliptic dataset from the given links.\n",
        "\n",
        "## Note: We temporarily uploaded our nodes.csv data as a LFS object in GitHub, but I just got an email saying that my quota has been depleted. If you cannot run the code for data download, please download our nodes.csv data from https://drive.google.com/file/d/1xOxc6VN0qkLjqBES1SXDjX1Kku7MNxp3/view?usp=sharing. Thanks! "
      ],
      "metadata": {
        "id": "NTe1HoYlJ7Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzlHyYgBJ-_5",
        "outputId": "f13dc59e-5abc-4294-c68c-b54a8a035058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.9\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.10.0%2Bcu113/torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.12\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.2.tar.gz (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.0.2-py3-none-any.whl (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 38.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.2-py3-none-any.whl size=535570 sha256=cb9e6c132156786427286ed244855cb725d664d01b13e853e626ff3e4dab307c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/08/13/2321517088bb2e95bfd0e45033bb9c923189e5b2078e0be4ef\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 rdflib-6.0.2 torch-geometric-2.0.2 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(rc={'axes.facecolor':'dimgrey', 'grid.color':'lightgrey'})\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch_scatter\n",
        "from torch_geometric.data import Data\n",
        "print(torch.__version__)\n",
        "\n",
        "# # The PyG built-in GCNConv\n",
        "# from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax, degree\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,roc_auc_score\n",
        "import scipy.sparse as scsp\n",
        "from sklearn.cluster import KMeans\n",
        "import copy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sh7sKWaKKC8",
        "outputId": "750e6d27-c853-47b2-9b1d-fd5372a5832c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_data_e = (r'https://raw.githubusercontent.com/yuchenWYC/'\n",
        "              r'Elliptic_dataset/master/edges.csv')\n",
        "edges = pd.read_csv(url_data_e)\n",
        "\n",
        "url_data_n = (r'https://media.githubusercontent.com/media/yuchenWYC/'\n",
        "              r'Elliptic_dataset/master/nodes.csv')\n",
        "nodes = pd.read_csv(url_data_n)"
      ],
      "metadata": {
        "id": "FKNcBMa3KMmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can take a look at how the preprocessed dataset looks like."
      ],
      "metadata": {
        "id": "16r7TLW8KRSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodes.iloc[0:2, 0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "oKiBEH5TKQDe",
        "outputId": "96f5ce3f-759d-43cd-d7ea-3b3a75985bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId</th>\n",
              "      <th>class</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>232438397</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.163054</td>\n",
              "      <td>1.963790</td>\n",
              "      <td>-0.646376</td>\n",
              "      <td>12.409294</td>\n",
              "      <td>-0.063725</td>\n",
              "      <td>9.782742</td>\n",
              "      <td>12.414558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>232029206</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.005027</td>\n",
              "      <td>0.578941</td>\n",
              "      <td>-0.091383</td>\n",
              "      <td>4.380281</td>\n",
              "      <td>-0.063725</td>\n",
              "      <td>4.667146</td>\n",
              "      <td>0.851305</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        txId  class  timestamp  ...         6         7          8\n",
              "0  232438397      0          1  ... -0.063725  9.782742  12.414558\n",
              "1  232029206      0          1  ... -0.063725  4.667146   0.851305\n",
              "\n",
              "[2 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edges.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "IR7hag0WKUfz",
        "outputId": "fb1cd970-dc94-4e93-b558-477851e2ca13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txId1</th>\n",
              "      <th>txId2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>232344069</td>\n",
              "      <td>27553029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3881097</td>\n",
              "      <td>232457116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>232051089</td>\n",
              "      <td>232470704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230473487</td>\n",
              "      <td>7089694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>231182296</td>\n",
              "      <td>14660781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       txId1      txId2\n",
              "0  232344069   27553029\n",
              "1    3881097  232457116\n",
              "2  232051089  232470704\n",
              "3  230473487    7089694\n",
              "4  231182296   14660781"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time-Step Splitting Script\n",
        "\n"
      ],
      "metadata": {
        "id": "pmSicCbIlrqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "4oBAIyIZB63k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Np_gIciQ7M44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def time_step_split_helper(new_nodes, new_edges):\n",
        "    \"\"\"\n",
        "    Split the graph and store node features, edges (represented by adjacency list),\n",
        "    and labels separately by timestamp t (from 1 to 49).\n",
        "\n",
        "    Args:\n",
        "        new_nodes     A dataframe of the node features\n",
        "        new_edges     A dataframe of the graph's adjacency list\n",
        "\n",
        "    Returns:\n",
        "        features_t    A list of (|N_t|, d) feature matrices by timestamp\n",
        "        edge_indices  A list of (2, |E_t|) adjacency list by timestamp\n",
        "        labels_t      A list of (|N_t|) labels by timestamp\n",
        "    \"\"\"\n",
        "\n",
        "    features =  torch.FloatTensor(new_nodes.iloc[:, 2:].to_numpy())\n",
        "    times = new_nodes.iloc[:, 2].to_numpy()\n",
        "    times = torch.LongTensor(times.reshape(len(times),))\n",
        "    labels = new_nodes.iloc[:, 1].to_numpy()\n",
        "    labels = torch.LongTensor(labels.reshape(len(labels),))\n",
        "\n",
        "    nodes_id = new_nodes.iloc[:, 0].to_numpy()\n",
        "    nodes_id = torch.LongTensor(nodes_id.reshape(len(nodes_id),))\n",
        "\n",
        "    min_t = torch.min(times) # 1\n",
        "    max_t = torch.max(times) # 49\n",
        "    \n",
        "    # Construct nodes of the directed graph for each time step;\n",
        "    # features by time step are stored in \"features_t\"; labels by\n",
        "    # time step are stored in \"labels_t\"\n",
        "    features_t = []\n",
        "    labels_t = []\n",
        "    \n",
        "    # Create a dictionary where\n",
        "    # <key, value> = <node_id, <<idx, node_index_in_time_t_subgraph>, <t, time_t>>>.\n",
        "    id2idx = {}\n",
        "    for t in range(min_t, max_t + 1):\n",
        "        features_t.append(features[times == t, :])\n",
        "        labels_t.append(labels[times == t])\n",
        "        nodes_t = nodes_id[times == t]\n",
        "        for i in range(nodes_t.shape[0]):\n",
        "            id2idx[nodes_t[i].item()] = {}\n",
        "            id2idx[nodes_t[i].item()]['idx'] = i\n",
        "            id2idx[nodes_t[i].item()]['t'] = t\n",
        "\n",
        "    # Construct adjacency lists of the directed graph (non-symmetric) for each time step;\n",
        "    # adjacency lists for each time step are stored in \"edge_indices\".\n",
        "    edge_idx_t = [[] for _ in range(min_t, max_t + 1)]\n",
        "    for index in range(new_edges.shape[0]):   \n",
        "        node1_t = id2idx[new_edges.iloc[index, 0]]['t']\n",
        "        node1_idx = id2idx[new_edges.iloc[index, 0]]['idx']\n",
        "        node2_t = id2idx[new_edges.iloc[index, 1]]['t']\n",
        "        node2_idx = id2idx[new_edges.iloc[index, 1]]['idx']\n",
        "        edge_idx_t[node1_t - 1].append([node1_idx, node2_idx]) # time_step starts from 1\n",
        "\n",
        "    edge_indices = [torch.LongTensor(edge_idx_t[i]).t() for i in range(len(edge_idx_t))]\n",
        "    return features_t, edge_indices, labels_t"
      ],
      "metadata": {
        "id": "i7GxtNsuKYa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_step_split(new_nodes, new_edges, device, train_lt = 31, val_lt = 36, test_lt = 49):\n",
        "    \"\"\"\n",
        "    Create and return the training, validation, and test set, splitted by time step,\n",
        "    where each subgraph at time t is considered as an input of GCN model.\n",
        "\n",
        "    Args:\n",
        "        new_nodes     A dataframe of the node features\n",
        "        new_edges     A dataframe of the graph's adjacency list\n",
        "        device        Computing device\n",
        "        train_lt      The last time step index of training set\n",
        "        val_lt        The last time step index of validation set\n",
        "        test_lt       The last time step index of test set\n",
        "\n",
        "    Returns:\n",
        "        data          A dictionary that stores training, validation, and test set,\n",
        "                        each value is a list of Data object\n",
        "        graph_info    A matrix where each row contains information of the time-step subgraph\n",
        "                      [time_step, num_of_nodes, num_of_edges, num_of_illicit_nodes]\n",
        "    \"\"\"\n",
        "    features_t, edge_indices, labels_t = time_step_split_helper(new_nodes, new_edges)\n",
        "\n",
        "    graph_info = np.zeros((len(labels_t), 4), dtype = np.int64)\n",
        "    for t in range(len(labels_t)):\n",
        "        graph_info[t, :] = np.array([t, features_t[t].shape[0], edge_indices[t].shape[1],\n",
        "                                     labels_t[t][labels_t[t] == 1].shape[0]])\n",
        "\n",
        "    train_idx, val_idx, test_idx = [np.arange(train_lt), np.arange(train_lt, val_lt),\n",
        "                                    np.arange(val_lt, test_lt)]\n",
        "    train_list = [Data(x = features_t[idx], edge_index = edge_indices[idx],\n",
        "                       y = labels_t[idx]).to(device) for idx in train_idx ]\n",
        "    val_list = [Data(x = features_t[idx], edge_index = edge_indices[idx],\n",
        "                     y = labels_t[idx]).to(device) for idx in val_idx ]\n",
        "    test_list = [Data(x = features_t[idx], edge_index = edge_indices[idx],\n",
        "                      y = labels_t[idx]).to(device) for idx in test_idx ]\n",
        "    data = {}\n",
        "    data['train'] = train_list\n",
        "    data['val'] = val_list\n",
        "    data['test'] = test_list\n",
        "\n",
        "    return data, graph_info"
      ],
      "metadata": {
        "id": "VvYxqptIKZiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, graph_info = time_step_split(nodes, edges, device)\n",
        "for key in data:\n",
        "  print(key, len(data[key]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VgxAOoSiZyq",
        "outputId": "a2f68707-f028-468d-e2c9-fd43c5c324dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 31\n",
            "val 5\n",
            "test 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def time_group_split(new_nodes, new_edges, device, train_lt = 31, val_lt = 36, test_lt = 49):\n",
        "    \"\"\"\n",
        "    Create and return the training, validation, and test set, splitted by specific\n",
        "    time step intervals, where the combination of subgraphs within the time step\n",
        "    interval is considered as an input of GCN model.\n",
        "\n",
        "    Args:\n",
        "        new_nodes     A dataframe of the node features\n",
        "        new_edges     A dataframe of the graph's adjacency list\n",
        "        device        Computing device\n",
        "        train_lt      The last time step index of training set\n",
        "        val_lt        The last time step index of validation set\n",
        "        test_lt       The last time step index of test set\n",
        "\n",
        "    Returns:\n",
        "        data          A dictionary that stores training, validation, and test set\n",
        "                        each value is one Data object\n",
        "    \"\"\"\n",
        "    features =  torch.FloatTensor(new_nodes.iloc[:, 2:].to_numpy())\n",
        "    times = new_nodes.iloc[:, 2].to_numpy()\n",
        "    times = torch.LongTensor(times.reshape(len(times),))\n",
        "    labels = new_nodes.iloc[:, 1].to_numpy()\n",
        "    labels = torch.LongTensor(labels.reshape(len(labels),))\n",
        "\n",
        "    nodes_id = new_nodes.iloc[:, 0].to_numpy()\n",
        "    nodes_id = torch.LongTensor(nodes_id.reshape(len(nodes_id),))\n",
        "    train_idx, val_idx, test_idx = [np.arange(1, train_lt + 1),\n",
        "                                    np.arange(train_lt + 1, val_lt + 1),\n",
        "                                    np.arange(val_lt + 1, test_lt + 1)]\n",
        "    data_names = {'train': train_idx, 'val': val_idx, 'test': test_idx}\n",
        "    \n",
        "    # Construct nodes of the directed graph for specific time step intervals.\n",
        "    # Features are stored in the given dataset name (train/val/test) of a dictionary,\n",
        "    # 'raw_data', with key \"features\"; labels are stored with key \"labels\".\n",
        "    min_t = torch.min(times) # 1\n",
        "    max_t = torch.max(times) # 49\n",
        "\n",
        "    id2idx = {}\n",
        "    raw_data = {}\n",
        "    for name in data_names.keys():\n",
        "        features_set = []\n",
        "        labels_set = []\n",
        "        Id_set = []\n",
        "        set_index = data_names[name]\n",
        "        for time in set_index:\n",
        "            features_set.append(features[times == time, :])\n",
        "            labels_set.append(labels[times == time])\n",
        "            Id_set.append(nodes_id[times == time])\n",
        "        features_set = torch.cat(features_set, 0)\n",
        "        labels_set = torch.cat(labels_set, 0)\n",
        "        Id_set = torch.cat(Id_set, 0)\n",
        "        for i in range((Id_set).shape[0]):\n",
        "            id2idx[Id_set[i].item()] = {}\n",
        "            id2idx[Id_set[i].item()]['idx'] = i\n",
        "            id2idx[Id_set[i].item()]['set_name'] = name\n",
        "        raw_data[name] = {'features': features_set, 'labels': labels_set}\n",
        "\n",
        "\n",
        "    # Construct adjacency lists of the directed graph (non-symmetric) for\n",
        "    # specific time intervals. Adjacency lists are stored with key \"edge_indices\".\n",
        "    edge_idx_set = {name: [] for name in data_names.keys()}\n",
        "    for index in range(new_edges.shape[0]): \n",
        "        node1_set = id2idx[new_edges.iloc[index, 0]]['set_name']\n",
        "        node1_idx = id2idx[new_edges.iloc[index, 0]]['idx']\n",
        "        node2_set = id2idx[new_edges.iloc[index, 1]]['set_name']\n",
        "        node2_idx = id2idx[new_edges.iloc[index, 1]]['idx']\n",
        "        edge_idx_set[node1_set].append([node1_idx, node2_idx]) # time_stamp starts from 1\n",
        "\n",
        "    for name in data_names.keys():\n",
        "        raw_data[name]['edge_indices'] = torch.LongTensor(edge_idx_set[name]).t()\n",
        "\n",
        "\n",
        "    # Construct the training, validation, test set by 'raw_data' and store\n",
        "    # in a dictionary, 'data'.\n",
        "    data = {}\n",
        "    for name in data_names.keys():\n",
        "        data[name] = Data(x = raw_data[name]['features'],\n",
        "                          edge_index = raw_data[name]['edge_indices'],\n",
        "                          y = raw_data[name]['labels']).to(device)\n",
        "    return data"
      ],
      "metadata": {
        "id": "ZcfAPY4uL2x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = time_group_split(nodes, edges, device)\n",
        "data2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx3cgpJigyjZ",
        "outputId": "0cdfdcd1-4c75-42b3-8fc7-8fc771b9f38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': Data(x=[13621, 166], edge_index=[2, 11576], y=[13621]),\n",
              " 'train': Data(x=[27615, 166], edge_index=[2, 21045], y=[27615]),\n",
              " 'val': Data(x=[5328, 166], edge_index=[2, 4003], y=[5328])}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Splitting Script\n"
      ],
      "metadata": {
        "id": "IKYuzV7wlm0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split_transd(new_nodes, new_edges, train_size, test_size, device, seed = 42):\n",
        "    \"\"\"\n",
        "    Create and return the training, validation, and test set by randomly splitting\n",
        "    the node indices to these three sets. Keep edge_index known for all sets.\n",
        "\n",
        "    Args:\n",
        "        new_nodes     A dataframe of the node features\n",
        "        new_edges     A dataframe of the graph's adjacency list\n",
        "        train_size    The node size proportion in training set\n",
        "        test_size     The node size proportion in test set\n",
        "        device        Computing device\n",
        "        seed          Random seed for data splitting\n",
        "\n",
        "    Returns:\n",
        "        data          A Data object that stores node features, edge_index, and labels\n",
        "        dict          A dictionary that stores training, validation, test set node indices\n",
        "    \"\"\"\n",
        "    features =  torch.FloatTensor(new_nodes.iloc[:, 2:].to_numpy())\n",
        "    labels = new_nodes.iloc[:, 1].to_numpy()\n",
        "    labels = torch.LongTensor(labels.reshape(len(labels),))\n",
        "    nodes_id = new_nodes.iloc[:, 0].to_numpy()\n",
        "\n",
        "    # Create a dictionary that maps nodeId to index in the dataframe.\n",
        "    id2idx = {}\n",
        "    for i in range(new_nodes.shape[0]):\n",
        "        id2idx[new_nodes.iloc[i, 0]] = i\n",
        "\n",
        "    # Construct edge_index with same node indexing as in features and labels\n",
        "    edge_idx = np.zeros((2, new_edges.shape[0]), dtype = np.int64)\n",
        "    for index in range(new_edges.shape[0]):   \n",
        "        node1 = id2idx[new_edges.iloc[index, 0]]\n",
        "        node2 = id2idx[new_edges.iloc[index, 1]]\n",
        "        edge_idx[:, index] = [node1, node2]\n",
        "    edge_index = torch.LongTensor(edge_idx)\n",
        "\n",
        "    train_index, test_index = train_test_split(np.arange(labels.shape[0]),\n",
        "                                               test_size = 1 - train_size,\n",
        "                                               random_state = 42)\n",
        "    val_index, test_index = train_test_split(test_index,\n",
        "                                             test_size = test_size / (1 - train_size),\n",
        "                                             random_state = 42)\n",
        "\n",
        "    # Construct the training, validation, test set and store\n",
        "    # in a dictionary, 'data'.\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    data = Data(x = features, edge_index = edge_index, y = labels).to(device)\n",
        "                  \n",
        "    return data, {'train': train_index, 'val': val_index, 'test': test_index}"
      ],
      "metadata": {
        "id": "MiXqunSYSuK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_sum = nodes.shape[0]\n",
        "train_node_size = np.sum(graph_info[0: 31, 1]) / node_sum\n",
        "test_node_size = np.sum(graph_info[36:, 1]) / node_sum\n",
        "data3, split_idx3 = random_split_transd(nodes, edges, train_size = train_node_size,\n",
        "                                        test_size = test_node_size, device = device)\n",
        "data3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obYw_oRjXyd0",
        "outputId": "db33f7d9-43b0-4779-bf39-e410d65703cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[46564, 166], edge_index=[2, 36624], y=[46564])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_node_size, test_node_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEV93PtZ4GlI",
        "outputId": "6bf0f3c2-6e4f-4cfb-f1a3-82797d3cc95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5930547203848466, 0.29252212009277556)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_split_ind(new_nodes, new_edges, train_size, test_size, device, seed = 42):\n",
        "    \"\"\"\n",
        "    Create and return the training, validation, and test set by randomly splitting\n",
        "    the node indices to these three sets. Keep only the node-induced edges within\n",
        "    each set.\n",
        "\n",
        "    Args:\n",
        "        new_nodes     A dataframe of the node features\n",
        "        new_edges     A dataframe of the graph's adjacency list\n",
        "        train_size    The node size proportion in training set\n",
        "        test_size     The node size proportion in test set\n",
        "        device        Computing device\n",
        "        seed          Random seed for data splitting\n",
        "\n",
        "    Returns:\n",
        "        data          A dictionary that stores training, validation, and test set\n",
        "                        each value is one Data object\n",
        "    \"\"\"\n",
        "    ## Create PyG graph separated by time (merge graphs in each set in train/val/test).\n",
        "    features =  torch.FloatTensor(new_nodes.iloc[:, 2:].to_numpy())\n",
        "    labels = new_nodes.iloc[:, 1].to_numpy()\n",
        "    labels = torch.LongTensor(labels.reshape(len(labels),))\n",
        "\n",
        "    nodes_id = new_nodes.iloc[:, 0].to_numpy()\n",
        "    nodes_id = torch.LongTensor(nodes_id.reshape(len(nodes_id),))\n",
        "\n",
        "    # Create random splitting node indices.\n",
        "    nodes_id_train, nodes_id_test, train_idx, test_idx = \\\n",
        "        train_test_split(nodes_id, range(nodes_id.shape[0]), test_size = 1 - train_size,\n",
        "                         random_state = seed)\n",
        "    nodes_id_valid, nodes_id_test, val_idx, test_idx = \\\n",
        "        train_test_split(nodes_id_test, test_idx, test_size = test_size / (1 - train_size),\n",
        "                         random_state = seed)\n",
        "    features_set = {'train': features[train_idx], 'val': features[val_idx],\n",
        "                    'test': features[test_idx]}\n",
        "    labels_set = {'train': labels[train_idx], 'val': labels[val_idx],\n",
        "                  'test': labels[test_idx]}\n",
        "\n",
        "    # Find the induced edge indices by the given node indices.\n",
        "    id2idx = {}\n",
        "    for i in range(nodes_id_train.shape[0]):\n",
        "        id2idx[int(nodes_id_train[i])] = (i, 'train')\n",
        "    for i in range(nodes_id_valid.shape[0]):\n",
        "        id2idx[int(nodes_id_valid[i])] = (i, 'val')\n",
        "    for i in range(nodes_id_test.shape[0]):\n",
        "        id2idx[int(nodes_id_test[i])] = (i, 'test')   \n",
        "\n",
        "    edge_index = {'train': [], 'val': [], 'test': []}\n",
        "    for i in range(new_edges.shape[0]):\n",
        "        node1 = id2idx[new_edges.iloc[i, 0]]\n",
        "        node2 = id2idx[new_edges.iloc[i, 1]]\n",
        "        if (node1[-1] == 'train' and node2[-1] == 'train'):\n",
        "            edge_index['train'].append([node1[0], node2[0]])\n",
        "        elif (node1[-1] == 'val' and node2[-1] == 'val'):\n",
        "            edge_index['val'].append([node1[0], node2[0]])\n",
        "        elif (node1[-1] == 'test' and node2[-1] == 'test'):\n",
        "            edge_index['test'].append([node1[0], node2[0]])\n",
        "\n",
        "    data = {}\n",
        "    for name in ['train', 'val', 'test']:\n",
        "        edge_index[name] = torch.LongTensor(edge_index[name]).t()\n",
        "        data[name] = Data(x = features_set[name], edge_index = edge_index[name],\n",
        "                          y = labels_set[name]).to(device)\n",
        "    train_data = data['train']\n",
        "    val_data = data['val']\n",
        "    test_data = data['test']\n",
        "                  \n",
        "    return data"
      ],
      "metadata": {
        "id": "niQiKcC4ipDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data4 = random_split_ind(nodes, edges, train_size = train_node_size,\n",
        "                         test_size = test_node_size, device = device)\n",
        "data4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVCBD0SAjdCy",
        "outputId": "2c81fb1f-88d8-42c6-df26-916bb9d4aa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test': Data(x=[13621, 166], edge_index=[2, 3205], y=[13621]),\n",
              " 'train': Data(x=[27615, 166], edge_index=[2, 12937], y=[27615]),\n",
              " 'val': Data(x=[5328, 166], edge_index=[2, 428], y=[5328])}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Community Splitting Script\n"
      ],
      "metadata": {
        "id": "N32hHDXolgjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def laplacian(A, alpha = 0.1):\n",
        "    \"\"\"\n",
        "    Returns the Laplacian matrix of the given adjacency matrix. For the directed\n",
        "    acyclic graph (not connected) with adjacency matrix A, we define a modified\n",
        "    Laplacian matrix as follows:\n",
        "            A_tilde = (1 - alpha) * (A + A^T) + alpha * 11^T\n",
        "            L = I - D_tilde^{-1/2} A_tilde D_tilde^{-1/2}\n",
        "    Args:\n",
        "        A             Adjacency matrix of certain graph\n",
        "        alpha         Smoothing constant that prevents isolated nodes\n",
        "\n",
        "    Returns:\n",
        "        L             Modified Laplacian matrix of the adjacency matrix A\n",
        "    \"\"\"\n",
        "    # A is sparse, csr format\n",
        "    A = (1 - alpha) * (A + A.T) + alpha * scsp.csr_matrix(np.outer(np.ones(A.shape[0]), np.ones(A.shape[0])))\n",
        "    D = scsp.diags(np.asarray(np.sum(A, axis = 0)).reshape(-1) ** (-1/2))\n",
        "    L = scsp.diags(np.ones(A.shape[0])) - D @ A @ D\n",
        "    return L\n",
        "\n",
        "def adj_list_to_mtx(n, edge_index):\n",
        "    \"\"\"\n",
        "    Create a csr-format adjacency matrix by the given adjacency list.\n",
        "    Args:\n",
        "        n             The number of nodes in the graph\n",
        "        edge_index    The (2, |E|) adjacency list of the graph\n",
        "\n",
        "    Returns:\n",
        "        a csr-format adjacency matrix\n",
        "    \"\"\"\n",
        "    edge_mtx = np.zeros((n, n))\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        node1 = int(edge_index[0, i])\n",
        "        node2 = int(edge_index[1, i])\n",
        "        edge_mtx[node1, node2] = 1\n",
        "\n",
        "    return scsp.csr_matrix(edge_mtx)\n",
        "\n",
        "def nearest_sum(arr, target):\n",
        "    \"\"\" \n",
        "    Get a combination of numbers in the given array that sums nearest to \n",
        "    the target number.\n",
        "    \n",
        "    Args:\n",
        "        arr      The given array\n",
        "        target   The target number\n",
        "\n",
        "    Returns:\n",
        "        resid           The residual between the summation and the target number\n",
        "        elt_idx_list    The indices of the subarray for summation\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(arr)\n",
        "    opt_arr = np.zeros((n + 1, target + 1))\n",
        "    for i in range(1, n + 1):\n",
        "        opt_arr[i, :] = opt_arr[i-1, :]\n",
        "        for j in np.arange(target, 0, step = -1):\n",
        "            if opt_arr[i, j] > 0 and j + arr[i - 1] <= target:\n",
        "                opt_arr[i, j + arr[i - 1]] += 1\n",
        "        opt_arr[i, arr[i - 1]] += 1\n",
        "    \n",
        "    elt_list = []\n",
        "    elt_idx_list = []\n",
        "    target_sum = target\n",
        "    idx = n\n",
        "    if (opt_arr[idx, target] == 0):\n",
        "        while opt_arr[idx, target_sum] == 0:\n",
        "            print(target_sum)\n",
        "            target_sum -= 1\n",
        "    resid = target - target_sum\n",
        "\n",
        "    while (idx > 0 and target_sum != 0):\n",
        "        if (opt_arr[idx, target_sum] - opt_arr[idx - 1, target_sum] > 0):\n",
        "            elt_list.append(arr[idx - 1])\n",
        "            elt_idx_list.append(idx - 1)\n",
        "            target_sum -= arr[idx - 1]\n",
        "        idx = idx - 1\n",
        "    return resid, elt_idx_list"
      ],
      "metadata": {
        "id": "4Xaw0oxal0NE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def community_split_transd(new_nodes, new_edges, train_size, test_size, device):\n",
        "    \"\"\"\n",
        "    Create and return the training, validation, and test set by merging small\n",
        "    clusters of the graphs. Keep edge_index known for all sets.\n",
        "\n",
        "    Args:\n",
        "        new_nodes     A dataframe of the node features\n",
        "        new_edges     A dataframe of the graph's adjacency list\n",
        "        train_size    The node size proportion in training set\n",
        "        test_size     The node size proportion in test set\n",
        "\n",
        "    Returns:\n",
        "        data          A Data object that stores node features, edge_index, and labels\n",
        "        dict          A dictionary that stores training, validation, test set node indices\n",
        "    \"\"\"\n",
        "    cluster_num = 500\n",
        "    features_t, edge_indices, labels_t = time_step_split_helper(new_nodes, new_edges)\n",
        "\n",
        "     # Construct the features, labels, and edge_index\n",
        "    features =  torch.FloatTensor(new_nodes.iloc[:, 2:].to_numpy())\n",
        "    labels = new_nodes.iloc[:, 1].to_numpy()\n",
        "    labels = torch.LongTensor(labels.reshape(len(labels),))\n",
        "    nodes_id = new_nodes.iloc[:, 0].to_numpy()\n",
        "    # Create a dictionary that maps nodeId to index in the dataframe.\n",
        "    id2idx = {}\n",
        "    for i in range(new_nodes.shape[0]):\n",
        "        id2idx[new_nodes.iloc[i, 0]] = i\n",
        "    # Construct edge_index with same node indexing as in features and labels\n",
        "    edge_idx = np.zeros((2, new_edges.shape[0]), dtype = np.int64)\n",
        "    for index in range(new_edges.shape[0]):   \n",
        "        node1 = id2idx[new_edges.iloc[index, 0]]\n",
        "        node2 = id2idx[new_edges.iloc[index, 1]]\n",
        "        edge_idx[:, index] = [node1, node2]\n",
        "    edge_index = torch.LongTensor(edge_idx)\n",
        "\n",
        "    # Perform spectral clustering on the entire graph.\n",
        "    # Since the entire graph's adjacency matrix A can be written as a block\n",
        "    # diagonal matrix (blocked by time steps), we can recreate the eigenvalues\n",
        "    # and eigenvectors of A by the eigenvalues and eigenvectors of blocks A_1,\n",
        "    # A_2, ..., A_49 of A.\n",
        "    t = 0\n",
        "    eval_dict = {}\n",
        "    node_num = []\n",
        "\n",
        "    for t in range(49): # max_t = 49\n",
        "        n = features_t[t].shape[0]\n",
        "        A = adj_list_to_mtx(n, edge_indices[t])\n",
        "        L = laplacian(A)\n",
        "        evals, evecs = scsp.linalg.eigsh(L, k = n // 40, which = 'SM')\n",
        "\n",
        "        for i in range(evals.shape[0]):\n",
        "            eval_dict[evals[i]] = [t, i, evecs[:, i]]\n",
        "        node_num.append(n)\n",
        "    \n",
        "    # 'node_blk' store node indices that mark time group separation.\n",
        "    node_blk = np.insert(np.cumsum(node_num), 0, 0)\n",
        "    # Block diagonal matrix has the first number-of-block (i.e., 49) smallest\n",
        "    # eigenvalues to be 0.\n",
        "    small_evals = np.sort(np.array([*eval_dict]))[49: (49 + cluster_num)]\n",
        "\n",
        "    node_mtx = np.zeros((node_blk[-1], cluster_num))\n",
        "    for i in range(small_evals.shape[0]):\n",
        "        eval = small_evals[i]\n",
        "        t, _, evec = eval_dict[eval]\n",
        "        node_mtx[node_blk[t]: node_blk[t + 1], i] = evec\n",
        "    \n",
        "    # Use K-means algorithm to create certain number of clusters (e.g., 500).\n",
        "    kmeans = KMeans(n_clusters = cluster_num, init = 'random', random_state = 42,\n",
        "                    n_init = 3, max_iter = 10).fit(node_mtx)\n",
        "    \n",
        "    comm_count = np.bincount(kmeans.labels_)\n",
        "\n",
        "    # Split and merge the clusters into three sets by the given number of nodes\n",
        "    # in each set.\n",
        "    node_num = new_nodes.shape[0]\n",
        "    train_num = int(np.round(node_sum * train_size))\n",
        "    val_num = int(np.round(node_sum * (1 - train_size - test_size)))\n",
        "\n",
        "    train_num_resid, train_clust_idx = nearest_sum(comm_count, train_num)\n",
        "    val_test_comm_count = np.delete(comm_count, train_clust_idx)\n",
        "    val_test_clust_idx = np.delete(np.arange(500), train_clust_idx)\n",
        "\n",
        "    val_num_resid, val_clust_idx_tmp = nearest_sum(val_test_comm_count, val_num)\n",
        "    val_clust_idx = val_test_clust_idx[val_clust_idx_tmp]\n",
        "    test_clust_idx = np.delete(np.arange(500), np.hstack((train_clust_idx, val_clust_idx)))\n",
        "\n",
        "    # Split node indices by their clusters into three datasets.\n",
        "    train_idx = []\n",
        "    val_idx = []\n",
        "    test_idx = []\n",
        "\n",
        "    train_clust_set = set(train_clust_idx)\n",
        "    val_clust_set = set(val_clust_idx)\n",
        "    test_clust_set = set(test_clust_idx)\n",
        "    for i in range(len(kmeans.labels_)):\n",
        "        if kmeans.labels_[i] in train_clust_set:\n",
        "            train_idx.append(i)\n",
        "        elif kmeans.labels_[i] in val_clust_set:\n",
        "            val_idx.append(i)\n",
        "        else:\n",
        "            test_idx.append(i)\n",
        "\n",
        "    if train_num_resid > 0:\n",
        "        train_idx.append(test_idx[-train_num_resid:])\n",
        "        test_idx = test_idx[:-train_num_resid]\n",
        "    if val_num_resid > 0:\n",
        "        val_idx.append(test_idx[-val_num_resid:])\n",
        "        test_idx = test_idx[:-val_num_resid]\n",
        "\n",
        "    train_idx = np.array(train_idx)\n",
        "    val_idx = np.array(val_idx)\n",
        "    test_idx = np.array(test_idx)\n",
        "    \n",
        "    # Construct the training, validation, test set and store\n",
        "    # in a dictionary, 'data'.\n",
        "    data = Data(x = features, edge_index = edge_index, y = labels).to(device)\n",
        "    \n",
        "    return data, {'train': train_idx, 'val': val_idx, 'test': test_idx}"
      ],
      "metadata": {
        "id": "Yx9ybvt6kwdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data5, split_idx5 = community_split_transd(nodes, edges, train_size = train_node_size,\n",
        "                                    test_size = test_node_size, device = device)\n",
        "data5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8OeE62qsLDX",
        "outputId": "26ce505a-8ee8-44e0-d219-04500aa5fbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[46564, 166], edge_index=[2, 36624], y=[46564])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN Model"
      ],
      "metadata": {
        "id": "GDDf7w6Yu7bV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers,\n",
        "                 dropout, return_embeds = False):\n",
        "        \"\"\"\n",
        "        Initialize a GCN model.\n",
        "        Args:\n",
        "            input_dim       Input dimension of node embeddings\n",
        "            hidden_dim      Hidden dimension of node embeddings\n",
        "            output_dim      Output dimension of node embeddings\n",
        "            num_layers      The number of GCN layers\n",
        "            dropout         The dropout ratio in (0, 1]\n",
        "                              (dropout: the probability of an element getting zeroed)\n",
        "            return_embeds   A boolean value determining whether we skip the\n",
        "                              classification layer and return node embeddings\n",
        "        \"\"\"\n",
        "\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        # Construct all convs\n",
        "        self.num_layers = num_layers\n",
        "        self.convs = torch.nn.ModuleList([GCNLayer(hidden_dim, hidden_dim, directed = False) \n",
        "                                                        for i in range(self.num_layers-1)])\n",
        "\n",
        "        # Construct batch normalization\n",
        "        self.bns = torch.nn.ModuleList([torch.nn.BatchNorm1d(hidden_dim)\n",
        "                                        for i in range(self.num_layers-1)])\n",
        "        # First GCN layer\n",
        "        self.convs[0] = GCNLayer(input_dim, hidden_dim, directed = False)\n",
        "        # Last GCN layer\n",
        "        self.last_conv = GCNLayer(hidden_dim, output_dim, directed = False)\n",
        "        self.softmax = torch.nn.LogSoftmax(dim = -1)\n",
        "        \n",
        "        self.dropout = dropout\n",
        "        self.return_embeds = return_embeds\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Reset all learnable parameters in GCN layers and Batch Normalization\n",
        "        Layers.\n",
        "        \"\"\"\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Produce a forward propagation of GCN model. Before the last GCN layer,\n",
        "        we transform the embedding (x) in the following sequence:\n",
        "          x -> GCN_Layer -> Batch_Norm -> ReLU -> Dropout.\n",
        "        At the last GCN layer, the following sequence is applied:\n",
        "          x -> GCN Layer -> Softmax -> output.\n",
        "        \n",
        "        Args:\n",
        "            x             The node embedding\n",
        "            edge_index    The adjacency list of the graph\n",
        "        \n",
        "        Returns:\n",
        "            out           The predictions of labels / the updated node embedding\n",
        "        \"\"\"\n",
        "        x = torch.clone(x.detach())\n",
        "        for l in range(self.num_layers - 1):\n",
        "            # Unweighted graph has weight 1.\n",
        "            x = self.convs[l](x, edge_index, torch.ones(edge_index.shape[1]))\n",
        "            x = self.bns[l](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p = self.dropout, training = self.training)\n",
        "\n",
        "        x = self.last_conv(x, edge_index, torch.ones(edge_index.shape[1]))\n",
        "        if self.return_embeds:\n",
        "            out = x\n",
        "        else:\n",
        "            out = self.softmax(x)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "kvAuospUumNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, bias = True, \n",
        "                 directed = False, self_loop = True, **kwargs):\n",
        "        \"\"\"\n",
        "        Initialize a GCN layer.\n",
        "        Args:\n",
        "            in_channels      In-channel dimension of node embeddings\n",
        "            out_channels     Out-channel dimension of node embeddings\n",
        "            bias             A boolean value determining whether we add a\n",
        "                                learnable bias term in linear transformation\n",
        "            directed         A boolean value determining whether we use directed\n",
        "                                message passing D^{-1}A or use symmetric normalized\n",
        "                                adjacency matrix D^{-1/2}AD^{-1/2}\n",
        "            self_loop        A boolean value determining whether we add a self-\n",
        "                                loop for each node\n",
        "        \"\"\"\n",
        "        super(GCNLayer, self).__init__(**kwargs, aggr = 'add')\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.directed = directed\n",
        "        self.self_loop = self_loop\n",
        "\n",
        "        # Define the layers needed for the message and update functions below.\n",
        "        # self.lin is the linear transformation that we apply to the embedding.\n",
        "        self.lin = nn.Linear(self.in_channels, self.out_channels, bias = bias)\n",
        "        \n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Reset all learnable parameters in the linear transformation.\n",
        "        \"\"\"\n",
        "        self.lin.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        \"\"\"\n",
        "        Produce a forward propagation of GCN layer.\n",
        "        \n",
        "        Args:\n",
        "            x             The node embedding\n",
        "            edge_index    The (2, |E|) adjacency list of the graph\n",
        "            edge_weight   The (|E|) vector specifying the edge weights in the graph\n",
        "                            (for unweighted graph, edge weight is 1)\n",
        "        \n",
        "        Returns:\n",
        "            An updated node embedding\n",
        "        \"\"\"\n",
        "        # Add self-loops to the adjacency matrix.\n",
        "        if self.self_loop:\n",
        "            edge_index, _ = add_self_loops(edge_index, num_nodes = x.size(0))\n",
        "            edge_weight = torch.cat((edge_weight, torch.ones(x.size(0))), dim = -1)\n",
        "        \n",
        "        # Apply linear transformation on node features.\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Compute normalization by updated node degree.\n",
        "        if self.directed:\n",
        "            row , _ = edge_index\n",
        "            deg = degree(row, x.size(0), dtype = x.dtype) # only out-degree\n",
        "            deg_inv = deg.pow(-1)\n",
        "            deg_inv[deg_inv == float('inf')] = 0\n",
        "            norm = deg_inv[row]\n",
        "        else:\n",
        "            row, col = edge_index\n",
        "            deg = degree(col, x.size(0), dtype = x.dtype)\n",
        "            deg_inv_sqrt = deg.pow(-0.5)\n",
        "            deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "            norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        return self.propagate(edge_index, x = (x, x), norm = norm, edge_weight = edge_weight)\n",
        "\n",
        "    def message(self, x_j, edge_weight, norm):\n",
        "        \"\"\"\n",
        "        Send the message of the neighboring node (i.e., x_j) to the source node (i.e., x_i).\n",
        "        \n",
        "        Args:\n",
        "            x_j           The embedding of the neighboring node of source node x_i\n",
        "            edge_weight   The edge weight of certain edge\n",
        "            norm          Normalization constant determined by self.directed\n",
        "        \n",
        "        Returns:\n",
        "            A message sending from the neighboring node to the source node\n",
        "        \"\"\"\n",
        "        return norm.view(-1, 1) * x_j * edge_weight.view(-1, 1)"
      ],
      "metadata": {
        "id": "wFlodgGHy37L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ind_time_step(model, train_data, optimizer, loss_fn):\n",
        "    \"\"\"\n",
        "    Train the model by using the given optimizer and loss_fn.\n",
        "    \n",
        "    Args:\n",
        "        model       The GCN model\n",
        "        train_data  The Data object that stores x, edge_index, and labels\n",
        "                      only for training set\n",
        "        optimizer   The optimizer\n",
        "        loss_fn     The loss function\n",
        "\n",
        "    Returns\n",
        "        The average prediction loss of each time step in the training set\n",
        "          by the given loss function\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    loss = torch.FloatTensor([0]*len(train_data)).to(device)\n",
        "    optimizer.zero_grad()\n",
        "    for i, data_t in enumerate(train_data):\n",
        "        train_slice = model.forward(data_t.x, data_t.edge_index)\n",
        "        train_label = data_t.y\n",
        "        loss[i] = loss_fn(train_slice, train_label)\n",
        "    loss.mean().backward()\n",
        "    optimizer.step()\n",
        "    return loss.mean().item()"
      ],
      "metadata": {
        "id": "L541j_4egwiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ind(model, train_data, optimizer, loss_fn):\n",
        "    \"\"\"\n",
        "    Train the model by using the given optimizer and loss_fn.\n",
        "    \n",
        "    Args:\n",
        "        model       The GCN model\n",
        "        train_data  The Data object that stores x, edge_index, and labels\n",
        "                      only for training set\n",
        "        optimizer   The optimizer\n",
        "        loss_fn     The loss function\n",
        "\n",
        "    Returns\n",
        "        The prediction loss by the given loss function\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_slice = model.forward(train_data.x, train_data.edge_index)\n",
        "    train_label = train_data.y\n",
        "    loss = loss_fn(train_slice, train_label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "3reBemC6-abG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transd(model, data, train_idx, optimizer, loss_fn):\n",
        "    \"\"\"\n",
        "    Train the model by using the given optimizer and loss_fn.\n",
        "    \n",
        "    Args:\n",
        "        model       The GCN model\n",
        "        data        The Data object that stores x, edge_index, and labels\n",
        "        train_idx   The node indices in the training set\n",
        "        optimizer   The optimizer\n",
        "        loss_fn     The loss function\n",
        "\n",
        "    Returns\n",
        "        The prediction loss by the given loss function\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    loss = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_slice = model.forward(data.x, data.edge_index)[train_idx]\n",
        "    train_label = data.y[train_idx]\n",
        "    loss = loss_fn(train_slice, train_label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "u-XitlKU5Shs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_ind_time_step(model, data, save_model_results=False):\n",
        "    \"\"\"\n",
        "    Test the model by using the given splitted datasets.\n",
        "\n",
        "    Args:\n",
        "        model                 The GCN model\n",
        "        data                  A dictionary of Data objects that store x, edge_index, and labels\n",
        "                                for three sets\n",
        "        save_model_results    A boolean determining whether we save the model results\n",
        "\n",
        "    Returns\n",
        "        The accuracy and auc-roc score of training, validation, and test set\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    # The output of model on each data sets\n",
        "    eval = {}\n",
        "    for name in data.keys():\n",
        "        data_list = data[name]\n",
        "        eval_report = []\n",
        "        eval_auc_roc = 0\n",
        "        for i,data_i in enumerate(data_list):\n",
        "            out = model.forward(data_i.x, data_i.edge_index)\n",
        "            y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "            acc = classification_report(torch.unsqueeze(data_i.y, -1),\n",
        "                                        y_pred,output_dict=True, zero_division=0)\n",
        "            eval_report.append(acc)\n",
        "            auc_roc = roc_auc_score(torch.unsqueeze(data_i.y, -1),y_pred)\n",
        "            eval_auc_roc += auc_roc\n",
        "        report = {}\n",
        "        for key in eval_report[0].keys():\n",
        "            if type(eval_report[0][key]) is dict:\n",
        "                df = pd.DataFrame([sub_report[key] for sub_report in eval_report])\n",
        "                report[key] = df.mean().to_dict()\n",
        "            else:\n",
        "                report[key] = np.mean(np.array([sub_report[key] for sub_report in eval_report]))\n",
        "        eval_auc_roc /= len(data_list)\n",
        "        eval[name] = {'report': pd.DataFrame(report), 'auc_roc': eval_auc_roc}\n",
        "    \n",
        "    ### TODO: what is the criterion to save the model results, the whole prediction\n",
        "    ### y_pred and y_true? or only the test sets' prediction?\n",
        "    if save_model_results:\n",
        "        print (\"Saving Model Predictions\")\n",
        "\n",
        "        data_new = {}\n",
        "        data_new ['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
        "\n",
        "        df = pd.DataFrame(data=data_new )\n",
        "        # Save locally as csv\n",
        "        df.to_csv('gcn_ind.csv', sep=',', index=False)\n",
        "    \n",
        "    return eval['train']['report'], eval['val']['report'], eval['test']['report'], \\\n",
        "           eval['train']['auc_roc'], eval['val']['auc_roc'], eval['test']['auc_roc']"
      ],
      "metadata": {
        "id": "9cH6NutPigVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_ind(model, data, save_model_results=False):\n",
        "    \"\"\"\n",
        "    Test the model by using the given splitted datasets.\n",
        "\n",
        "    Args:\n",
        "        model                 The GCN model\n",
        "        data                  A dictionary of Data objects that store x, edge_index, and labels\n",
        "                                for three sets\n",
        "        save_model_results    A boolean determining whether we save the model results\n",
        "\n",
        "    Returns\n",
        "        The accuracy and auc-roc score of training, validation, and test set\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    # The output of model on each data sets\n",
        "    train_out = model.forward(data['train'].x, data['train'].edge_index)\n",
        "    train_pred = train_out.argmax(dim=-1, keepdim=True)\n",
        "    train_acc = classification_report(torch.unsqueeze(data['train'].y, -1),\n",
        "                                      train_pred, zero_division=0)\n",
        "    train_auc_roc = roc_auc_score(torch.unsqueeze(data['train'].y, -1),\n",
        "                                  train_pred)\n",
        "    \n",
        "    val_out = model.forward(data['val'].x, data['val'].edge_index)\n",
        "    val_pred = val_out.argmax(dim=-1, keepdim=True)\n",
        "    val_acc = classification_report(torch.unsqueeze(data['val'].y, -1),\n",
        "                                    val_pred, zero_division=0)\n",
        "    val_auc_roc = roc_auc_score(torch.unsqueeze(data['val'].y, -1),\n",
        "                                  val_pred)\n",
        "    \n",
        "    test_out = model.forward(data['test'].x, data['test'].edge_index)\n",
        "    test_pred = test_out.argmax(dim=-1, keepdim=True)\n",
        "    test_acc = classification_report(torch.unsqueeze(data['test'].y, -1),\n",
        "                                     test_pred, zero_division=0)\n",
        "    test_auc_roc = roc_auc_score(torch.unsqueeze(data['test'].y, -1),\n",
        "                                  test_pred)\n",
        "    \n",
        "    ### TODO: what is the criterion to save the model results, the whole prediction\n",
        "    ### y_pred and y_true? or only the test sets' prediction?\n",
        "    if save_model_results:\n",
        "        print (\"Saving Model Predictions\")\n",
        "\n",
        "        data = {}\n",
        "        data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
        "\n",
        "        df = pd.DataFrame(data=data)\n",
        "        # Save locally as csv\n",
        "        df.to_csv('gcn_ind.csv', sep=',', index=False)\n",
        "    \n",
        "    return train_acc, val_acc, test_acc, \\\n",
        "           train_auc_roc, val_auc_roc, test_auc_roc"
      ],
      "metadata": {
        "id": "MupZFD-aBK8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test_transd(model, data, split_idx, save_model_results=False):\n",
        "    \"\"\"\n",
        "    Test the model by using the given split_idx.\n",
        "\n",
        "    Args:\n",
        "        model                 The GCN model\n",
        "        data                  The Data object that stores x, edge_index, and labels\n",
        "        split_idx             A dictionary that stores node indices for three sets\n",
        "        save_model_results    A boolean determining whether we save the model results\n",
        "\n",
        "    Returns\n",
        "        The accuracy and auc-roc score of training, validation, and test set\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    # The output of model on all data\n",
        "    out = model.forward(data.x, data.edge_index)\n",
        "    \n",
        "    train_index = split_idx['train']\n",
        "    val_index = split_idx['val']\n",
        "    test_index = split_idx['test']\n",
        "\n",
        "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
        "    train_acc = classification_report(torch.unsqueeze(data.y[train_index], -1),\n",
        "                                      y_pred[train_index], zero_division=0)\n",
        "    valid_acc = classification_report(torch.unsqueeze(data.y[val_index], -1),\n",
        "                                      y_pred[val_index], zero_division=0)\n",
        "    valid_accuracy = classification_report(torch.unsqueeze(data.y[val_index], -1),\n",
        "                                      y_pred[val_index], output_dict=True,\n",
        "                                      zero_division=0)['accuracy']\n",
        "    test_acc = classification_report(torch.unsqueeze(data.y[test_index], -1),\n",
        "                                     y_pred[test_index], zero_division=0)\n",
        "    train_auc_roc = roc_auc_score(torch.unsqueeze(data.y[train_index], -1),\n",
        "                                      y_pred[train_index])\n",
        "    val_auc_roc = roc_auc_score(torch.unsqueeze(data.y[val_index], -1),\n",
        "                                      y_pred[val_index])\n",
        "    test_auc_roc = roc_auc_score(torch.unsqueeze(data.y[test_index], -1),\n",
        "                                      y_pred[test_index])\n",
        "    \n",
        "    if save_model_results:\n",
        "        print (\"Saving Model Predictions\")\n",
        "\n",
        "        data = {}\n",
        "        data['y_pred'] = y_pred.view(-1).cpu().detach().numpy()\n",
        "\n",
        "        df = pd.DataFrame(data=data)\n",
        "        # Save locally as csv\n",
        "        df.to_csv('gcn_transd.csv', sep=',', index=False)\n",
        "    \n",
        "    return train_acc, valid_acc, test_acc, \\\n",
        "           train_auc_roc, val_auc_roc, test_auc_roc"
      ],
      "metadata": {
        "id": "odY8OTVE-7PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 2,\n",
        "    'hidden_dim': 256,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 50,\n",
        "    'label_weight': torch.Tensor([0.5, 0.5])\n",
        "}\n",
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU19A7PTA1L9",
        "outputId": "a77a1f59-8f05-40f6-f086-1381723eb0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'device': 'cpu',\n",
              " 'dropout': 0.5,\n",
              " 'epochs': 50,\n",
              " 'hidden_dim': 256,\n",
              " 'label_weight': tensor([0.5000, 0.5000]),\n",
              " 'lr': 0.01,\n",
              " 'num_layers': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random split & community split - transductive\n",
        "Note: Feed \"data5\" into the model if we were to run community split, \"data3\" to run random split.\n"
      ],
      "metadata": {
        "id": "ipydPQPu7QFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(data5.x.shape[1], args['hidden_dim'],\n",
        "            2, args['num_layers'], args['dropout']).to(device)"
      ],
      "metadata": {
        "id": "WHXg7k51A3uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = torch.nn.NLLLoss(weight=args['label_weight'])\n",
        "\n",
        "best_model = None\n",
        "best_valid_auc = 0\n",
        "best_result = None\n",
        "losses = []\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "    # train with random split\n",
        "    loss = train_transd(model, data3, split_idx3['train'], optimizer, loss_fn)\n",
        "    losses.append(loss)\n",
        "    result = test_transd(model, data3, split_idx3)\n",
        "    train_acc, val_acc, test_acc, train_auc, val_auc, test_auc = result \n",
        "    if val_auc > best_valid_auc:\n",
        "        best_valid_auc = val_auc\n",
        "        best_model = copy.deepcopy(model)\n",
        "        best_result = [train_acc, val_acc, test_acc, train_auc, val_auc, test_auc]\n",
        "\n",
        "    print('Epoch: {:02},'.format(epoch),\n",
        "          'Loss:{:.4f}'.format(loss),\n",
        "          'Train:\\n{}\\n'.format(train_acc),\n",
        "          'Train_auc_roc: {}'.format(train_auc),\n",
        "          '\\n\\n'\n",
        "          'Valid:\\n{}\\n'.format(val_acc),\n",
        "          'Val_auc_roc: {}'.format(val_auc),\n",
        "          '\\n\\n'\n",
        "          'Test:\\n{}\\n'.format(test_acc),\n",
        "          'Test_auc_roc: {}'.format(test_auc),\n",
        "          '\\n'\n",
        "          )\n",
        "  "
      ],
      "metadata": {
        "id": "v4YLuuBdA6PG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca28c46b-f509-4ecf-b317-a02278dd1317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss:1.0271 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94     24915\n",
            "           1       0.44      0.21      0.28      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.68      0.59      0.61     27615\n",
            "weighted avg       0.87      0.90      0.88     27615\n",
            "\n",
            " Train_auc_roc: 0.588975405266796 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95      4821\n",
            "           1       0.46      0.21      0.29       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.69      0.59      0.62      5328\n",
            "weighted avg       0.88      0.90      0.88      5328\n",
            "\n",
            " Val_auc_roc: 0.5910010322197388 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94     12283\n",
            "           1       0.42      0.20      0.28      1338\n",
            "\n",
            "    accuracy                           0.89     13621\n",
            "   macro avg       0.67      0.59      0.61     13621\n",
            "weighted avg       0.87      0.89      0.88     13621\n",
            "\n",
            " Test_auc_roc: 0.5869157634836729 \n",
            "\n",
            "Epoch: 02, Loss:0.3343 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       1.00      0.01      0.02      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.95      0.50      0.48     27615\n",
            "weighted avg       0.91      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5044444444444445 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95      4821\n",
            "           1       1.00      0.01      0.03       507\n",
            "\n",
            "    accuracy                           0.91      5328\n",
            "   macro avg       0.95      0.51      0.49      5328\n",
            "weighted avg       0.91      0.91      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5069033530571992 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       1.00      0.01      0.02      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.95      0.51      0.48     13621\n",
            "weighted avg       0.91      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5052316890881914 \n",
            "\n",
            "Epoch: 03, Loss:0.2313 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 04, Loss:0.2563 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 05, Loss:0.2563 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 06, Loss:0.2410 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 07, Loss:0.2244 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 08, Loss:0.2133 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 09, Loss:0.2117 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 10, Loss:0.2108 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 11, Loss:0.2095 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 12, Loss:0.2088 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 13, Loss:0.2072 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 14, Loss:0.2058 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 15, Loss:0.2030 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 16, Loss:0.1989 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       0.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.45      0.50      0.47     27615\n",
            "weighted avg       0.81      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 17, Loss:0.1957 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       1.00      0.00      0.00      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.95      0.50      0.47     27615\n",
            "weighted avg       0.91      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5001851851851852 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      4821\n",
            "           1       0.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.90      5328\n",
            "   macro avg       0.45      0.50      0.48      5328\n",
            "weighted avg       0.82      0.90      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       0.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.45      0.50      0.47     13621\n",
            "weighted avg       0.81      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5 \n",
            "\n",
            "Epoch: 18, Loss:0.1925 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     24915\n",
            "           1       1.00      0.00      0.01      2700\n",
            "\n",
            "    accuracy                           0.90     27615\n",
            "   macro avg       0.95      0.50      0.48     27615\n",
            "weighted avg       0.91      0.90      0.86     27615\n",
            "\n",
            " Train_auc_roc: 0.5022222222222222 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95      4821\n",
            "           1       1.00      0.00      0.00       507\n",
            "\n",
            "    accuracy                           0.91      5328\n",
            "   macro avg       0.95      0.50      0.48      5328\n",
            "weighted avg       0.91      0.91      0.86      5328\n",
            "\n",
            " Val_auc_roc: 0.5009861932938856 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95     12283\n",
            "           1       1.00      0.00      0.00      1338\n",
            "\n",
            "    accuracy                           0.90     13621\n",
            "   macro avg       0.95      0.50      0.48     13621\n",
            "weighted avg       0.91      0.90      0.86     13621\n",
            "\n",
            " Test_auc_roc: 0.5011210762331838 \n",
            "\n",
            "Epoch: 19, Loss:0.1895 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95     24915\n",
            "           1       0.99      0.07      0.13      2700\n",
            "\n",
            "    accuracy                           0.91     27615\n",
            "   macro avg       0.95      0.53      0.54     27615\n",
            "weighted avg       0.92      0.91      0.87     27615\n",
            "\n",
            " Train_auc_roc: 0.5336836354717149 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95      4821\n",
            "           1       1.00      0.06      0.11       507\n",
            "\n",
            "    accuracy                           0.91      5328\n",
            "   macro avg       0.95      0.53      0.53      5328\n",
            "weighted avg       0.92      0.91      0.87      5328\n",
            "\n",
            " Val_auc_roc: 0.5295857988165681 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95     12283\n",
            "           1       1.00      0.06      0.12      1338\n",
            "\n",
            "    accuracy                           0.91     13621\n",
            "   macro avg       0.95      0.53      0.53     13621\n",
            "weighted avg       0.92      0.91      0.87     13621\n",
            "\n",
            " Test_auc_roc: 0.5306427503736921 \n",
            "\n",
            "Epoch: 20, Loss:0.1864 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     24915\n",
            "           1       0.98      0.20      0.33      2700\n",
            "\n",
            "    accuracy                           0.92     27615\n",
            "   macro avg       0.95      0.60      0.64     27615\n",
            "weighted avg       0.93      0.92      0.90     27615\n",
            "\n",
            " Train_auc_roc: 0.5975971636898788 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96      4821\n",
            "           1       0.99      0.18      0.30       507\n",
            "\n",
            "    accuracy                           0.92      5328\n",
            "   macro avg       0.95      0.59      0.63      5328\n",
            "weighted avg       0.93      0.92      0.90      5328\n",
            "\n",
            " Val_auc_roc: 0.5886536835270739 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     12283\n",
            "           1       0.98      0.19      0.31      1338\n",
            "\n",
            "    accuracy                           0.92     13621\n",
            "   macro avg       0.95      0.59      0.63     13621\n",
            "weighted avg       0.92      0.92      0.89     13621\n",
            "\n",
            " Test_auc_roc: 0.5924721019377712 \n",
            "\n",
            "Epoch: 21, Loss:0.1850 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     24915\n",
            "           1       0.96      0.27      0.42      2700\n",
            "\n",
            "    accuracy                           0.93     27615\n",
            "   macro avg       0.94      0.63      0.69     27615\n",
            "weighted avg       0.93      0.93      0.91     27615\n",
            "\n",
            " Train_auc_roc: 0.6327513546056592 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      4821\n",
            "           1       0.95      0.24      0.38       507\n",
            "\n",
            "    accuracy                           0.93      5328\n",
            "   macro avg       0.94      0.62      0.67      5328\n",
            "weighted avg       0.93      0.93      0.91      5328\n",
            "\n",
            " Val_auc_roc: 0.6196933043182623 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     12283\n",
            "           1       0.96      0.26      0.41      1338\n",
            "\n",
            "    accuracy                           0.93     13621\n",
            "   macro avg       0.94      0.63      0.69     13621\n",
            "weighted avg       0.93      0.93      0.91     13621\n",
            "\n",
            " Test_auc_roc: 0.6312619967539322 \n",
            "\n",
            "Epoch: 22, Loss:0.1836 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     24915\n",
            "           1       0.94      0.33      0.48      2700\n",
            "\n",
            "    accuracy                           0.93     27615\n",
            "   macro avg       0.94      0.66      0.72     27615\n",
            "weighted avg       0.93      0.93      0.92     27615\n",
            "\n",
            " Train_auc_roc: 0.6618190737396036 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96      4821\n",
            "           1       0.94      0.31      0.46       507\n",
            "\n",
            "    accuracy                           0.93      5328\n",
            "   macro avg       0.94      0.65      0.71      5328\n",
            "weighted avg       0.93      0.93      0.92      5328\n",
            "\n",
            " Val_auc_roc: 0.6528090246198522 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96     12283\n",
            "           1       0.93      0.31      0.46      1338\n",
            "\n",
            "    accuracy                           0.93     13621\n",
            "   macro avg       0.93      0.65      0.71     13621\n",
            "weighted avg       0.93      0.93      0.91     13621\n",
            "\n",
            " Test_auc_roc: 0.6529915080658223 \n",
            "\n",
            "Epoch: 23, Loss:0.1804 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97     24915\n",
            "           1       0.92      0.40      0.56      2700\n",
            "\n",
            "    accuracy                           0.94     27615\n",
            "   macro avg       0.93      0.70      0.76     27615\n",
            "weighted avg       0.94      0.94      0.93     27615\n",
            "\n",
            " Train_auc_roc: 0.6976784400294335 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      4821\n",
            "           1       0.93      0.39      0.55       507\n",
            "\n",
            "    accuracy                           0.94      5328\n",
            "   macro avg       0.93      0.69      0.76      5328\n",
            "weighted avg       0.94      0.94      0.93      5328\n",
            "\n",
            " Val_auc_roc: 0.6937105783498967 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.96     12283\n",
            "           1       0.90      0.37      0.53      1338\n",
            "\n",
            "    accuracy                           0.93     13621\n",
            "   macro avg       0.92      0.68      0.75     13621\n",
            "weighted avg       0.93      0.93      0.92     13621\n",
            "\n",
            " Test_auc_roc: 0.683778374646646 \n",
            "\n",
            "Epoch: 24, Loss:0.1779 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97     24915\n",
            "           1       0.90      0.45      0.60      2700\n",
            "\n",
            "    accuracy                           0.94     27615\n",
            "   macro avg       0.92      0.72      0.78     27615\n",
            "weighted avg       0.94      0.94      0.93     27615\n",
            "\n",
            " Train_auc_roc: 0.7214250674515575 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97      4821\n",
            "           1       0.91      0.43      0.59       507\n",
            "\n",
            "    accuracy                           0.94      5328\n",
            "   macro avg       0.93      0.71      0.78      5328\n",
            "weighted avg       0.94      0.94      0.93      5328\n",
            "\n",
            " Val_auc_roc: 0.7137983599857134 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97     12283\n",
            "           1       0.87      0.41      0.56      1338\n",
            "\n",
            "    accuracy                           0.94     13621\n",
            "   macro avg       0.90      0.70      0.76     13621\n",
            "weighted avg       0.93      0.94      0.93     13621\n",
            "\n",
            " Test_auc_roc: 0.7013231918359827 \n",
            "\n",
            "Epoch: 25, Loss:0.1754 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     24915\n",
            "           1       0.88      0.48      0.62      2700\n",
            "\n",
            "    accuracy                           0.94     27615\n",
            "   macro avg       0.91      0.74      0.80     27615\n",
            "weighted avg       0.94      0.94      0.94     27615\n",
            "\n",
            " Train_auc_roc: 0.738014248444712 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      4821\n",
            "           1       0.88      0.47      0.61       507\n",
            "\n",
            "    accuracy                           0.94      5328\n",
            "   macro avg       0.91      0.73      0.79      5328\n",
            "weighted avg       0.94      0.94      0.94      5328\n",
            "\n",
            " Val_auc_roc: 0.7311877645753477 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.99      0.97     12283\n",
            "           1       0.84      0.44      0.58      1338\n",
            "\n",
            "    accuracy                           0.94     13621\n",
            "   macro avg       0.89      0.72      0.77     13621\n",
            "weighted avg       0.93      0.94      0.93     13621\n",
            "\n",
            " Test_auc_roc: 0.7173732407144074 \n",
            "\n",
            "Epoch: 26, Loss:0.1733 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     24915\n",
            "           1       0.85      0.52      0.64      2700\n",
            "\n",
            "    accuracy                           0.94     27615\n",
            "   macro avg       0.90      0.75      0.81     27615\n",
            "weighted avg       0.94      0.94      0.94     27615\n",
            "\n",
            " Train_auc_roc: 0.7543425424220127 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      4821\n",
            "           1       0.84      0.51      0.63       507\n",
            "\n",
            "    accuracy                           0.94      5328\n",
            "   macro avg       0.90      0.75      0.80      5328\n",
            "weighted avg       0.94      0.94      0.94      5328\n",
            "\n",
            " Val_auc_roc: 0.7493559366136073 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     12283\n",
            "           1       0.82      0.48      0.61      1338\n",
            "\n",
            "    accuracy                           0.94     13621\n",
            "   macro avg       0.88      0.74      0.79     13621\n",
            "weighted avg       0.93      0.94      0.93     13621\n",
            "\n",
            " Test_auc_roc: 0.7353324566492243 \n",
            "\n",
            "Epoch: 27, Loss:0.1712 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     24915\n",
            "           1       0.84      0.55      0.66      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.90      0.77      0.82     27615\n",
            "weighted avg       0.94      0.95      0.94     27615\n",
            "\n",
            " Train_auc_roc: 0.7692604856512142 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      4821\n",
            "           1       0.82      0.53      0.64       507\n",
            "\n",
            "    accuracy                           0.94      5328\n",
            "   macro avg       0.88      0.76      0.81      5328\n",
            "weighted avg       0.94      0.94      0.94      5328\n",
            "\n",
            " Val_auc_roc: 0.7580770274035317 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     12283\n",
            "           1       0.80      0.51      0.62      1338\n",
            "\n",
            "    accuracy                           0.94     13621\n",
            "   macro avg       0.88      0.75      0.80     13621\n",
            "weighted avg       0.93      0.94      0.93     13621\n",
            "\n",
            " Test_auc_roc: 0.7479785701603453 \n",
            "\n",
            "Epoch: 28, Loss:0.1688 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     24915\n",
            "           1       0.83      0.58      0.68      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.89      0.78      0.83     27615\n",
            "weighted avg       0.94      0.95      0.94     27615\n",
            "\n",
            " Train_auc_roc: 0.7814161482373403 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      4821\n",
            "           1       0.81      0.55      0.65       507\n",
            "\n",
            "    accuracy                           0.94      5328\n",
            "   macro avg       0.88      0.77      0.81      5328\n",
            "weighted avg       0.94      0.94      0.94      5328\n",
            "\n",
            " Val_auc_roc: 0.7681991631778621 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97     12283\n",
            "           1       0.80      0.54      0.65      1338\n",
            "\n",
            "    accuracy                           0.94     13621\n",
            "   macro avg       0.88      0.76      0.81     13621\n",
            "weighted avg       0.94      0.94      0.94     13621\n",
            "\n",
            " Test_auc_roc: 0.7646392190550528 \n",
            "\n",
            "Epoch: 29, Loss:0.1673 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     24915\n",
            "           1       0.83      0.60      0.70      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.89      0.79      0.83     27615\n",
            "weighted avg       0.95      0.95      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.7944128927241509 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      4821\n",
            "           1       0.80      0.58      0.68       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.88      0.78      0.82      5328\n",
            "weighted avg       0.94      0.95      0.94      5328\n",
            "\n",
            " Val_auc_roc: 0.7842384587155062 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97     12283\n",
            "           1       0.80      0.57      0.67      1338\n",
            "\n",
            "    accuracy                           0.94     13621\n",
            "   macro avg       0.88      0.78      0.82     13621\n",
            "weighted avg       0.94      0.94      0.94     13621\n",
            "\n",
            " Test_auc_roc: 0.7790577154833925 \n",
            "\n",
            "Epoch: 30, Loss:0.1647 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     24915\n",
            "           1       0.82      0.62      0.71      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.89      0.80      0.84     27615\n",
            "weighted avg       0.95      0.95      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.8029204852052533 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      4821\n",
            "           1       0.79      0.60      0.68       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.87      0.79      0.83      5328\n",
            "weighted avg       0.94      0.95      0.94      5328\n",
            "\n",
            " Val_auc_roc: 0.7911945887629195 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     12283\n",
            "           1       0.80      0.59      0.68      1338\n",
            "\n",
            "    accuracy                           0.94     13621\n",
            "   macro avg       0.88      0.79      0.82     13621\n",
            "weighted avg       0.94      0.94      0.94     13621\n",
            "\n",
            " Test_auc_roc: 0.7851255341305026 \n",
            "\n",
            "Epoch: 31, Loss:0.1625 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     24915\n",
            "           1       0.82      0.63      0.72      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.89      0.81      0.84     27615\n",
            "weighted avg       0.95      0.95      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.8087460699712355 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      4821\n",
            "           1       0.79      0.62      0.69       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.87      0.80      0.83      5328\n",
            "weighted avg       0.94      0.95      0.94      5328\n",
            "\n",
            " Val_auc_roc: 0.7989804221913742 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     12283\n",
            "           1       0.80      0.59      0.68      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.88      0.79      0.83     13621\n",
            "weighted avg       0.94      0.95      0.94     13621\n",
            "\n",
            " Test_auc_roc: 0.7891140269822535 \n",
            "\n",
            "Epoch: 32, Loss:0.1612 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     24915\n",
            "           1       0.83      0.64      0.72      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.89      0.81      0.85     27615\n",
            "weighted avg       0.95      0.95      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.8127754364840458 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      4821\n",
            "           1       0.80      0.63      0.70       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.88      0.81      0.84      5328\n",
            "weighted avg       0.95      0.95      0.95      5328\n",
            "\n",
            " Val_auc_roc: 0.8061949140164639 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     12283\n",
            "           1       0.80      0.60      0.69      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.88      0.79      0.83     13621\n",
            "weighted avg       0.94      0.95      0.94     13621\n",
            "\n",
            " Test_auc_roc: 0.7928916544272853 \n",
            "\n",
            "Epoch: 33, Loss:0.1587 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     24915\n",
            "           1       0.83      0.64      0.73      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.90      0.82      0.85     27615\n",
            "weighted avg       0.95      0.95      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.8154437309073072 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      4821\n",
            "           1       0.81      0.64      0.71       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.89      0.81      0.84      5328\n",
            "weighted avg       0.95      0.95      0.95      5328\n",
            "\n",
            " Val_auc_roc: 0.8096720585112717 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     12283\n",
            "           1       0.80      0.60      0.69      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.88      0.79      0.83     13621\n",
            "weighted avg       0.94      0.95      0.94     13621\n",
            "\n",
            " Test_auc_roc: 0.7913081407129106 \n",
            "\n",
            "Epoch: 34, Loss:0.1570 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     24915\n",
            "           1       0.84      0.65      0.73      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.90      0.82      0.85     27615\n",
            "weighted avg       0.95      0.95      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.8174515575177826 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      4821\n",
            "           1       0.82      0.63      0.71       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.89      0.81      0.84      5328\n",
            "weighted avg       0.95      0.95      0.95      5328\n",
            "\n",
            " Val_auc_roc: 0.8074394690880258 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     12283\n",
            "           1       0.81      0.60      0.69      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.79      0.83     13621\n",
            "weighted avg       0.94      0.95      0.94     13621\n",
            "\n",
            " Test_auc_roc: 0.7932506823690963 \n",
            "\n",
            "Epoch: 35, Loss:0.1558 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98     24915\n",
            "           1       0.85      0.65      0.74      2700\n",
            "\n",
            "    accuracy                           0.95     27615\n",
            "   macro avg       0.91      0.82      0.86     27615\n",
            "weighted avg       0.95      0.95      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.8199948714518251 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      4821\n",
            "           1       0.84      0.63      0.72       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.90      0.81      0.85      5328\n",
            "weighted avg       0.95      0.95      0.95      5328\n",
            "\n",
            " Val_auc_roc: 0.8080617466238069 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     12283\n",
            "           1       0.82      0.61      0.70      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.80      0.83     13621\n",
            "weighted avg       0.94      0.95      0.94     13621\n",
            "\n",
            " Test_auc_roc: 0.7961107669197052 \n",
            "\n",
            "Epoch: 36, Loss:0.1550 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98     24915\n",
            "           1       0.85      0.66      0.75      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.83      0.86     27615\n",
            "weighted avg       0.95      0.96      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.8253004660289429 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      4821\n",
            "           1       0.84      0.64      0.73       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.90      0.81      0.85      5328\n",
            "weighted avg       0.95      0.95      0.95      5328\n",
            "\n",
            " Val_auc_roc: 0.8122139456446095 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     12283\n",
            "           1       0.82      0.61      0.70      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.80      0.84     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.7980606406438493 \n",
            "\n",
            "Epoch: 37, Loss:0.1523 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     24915\n",
            "           1       0.85      0.67      0.75      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.83      0.86     27615\n",
            "weighted avg       0.95      0.96      0.95     27615\n",
            "\n",
            " Train_auc_roc: 0.8297294133386849 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98      4821\n",
            "           1       0.84      0.65      0.73       507\n",
            "\n",
            "    accuracy                           0.95      5328\n",
            "   macro avg       0.90      0.82      0.85      5328\n",
            "weighted avg       0.95      0.95      0.95      5328\n",
            "\n",
            " Val_auc_roc: 0.8179236795626629 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97     12283\n",
            "           1       0.82      0.63      0.71      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.81      0.84     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8073622359192959 \n",
            "\n",
            "Epoch: 38, Loss:0.1516 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     24915\n",
            "           1       0.85      0.69      0.76      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.84      0.87     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8372709434298838 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      4821\n",
            "           1       0.83      0.66      0.74       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.90      0.83      0.86      5328\n",
            "weighted avg       0.95      0.96      0.95      5328\n",
            "\n",
            " Val_auc_roc: 0.825398374223227 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     12283\n",
            "           1       0.82      0.64      0.72      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.81      0.85     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8133079345631493 \n",
            "\n",
            "Epoch: 39, Loss:0.1493 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     24915\n",
            "           1       0.84      0.70      0.76      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.84      0.87     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.84324614801436 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      4821\n",
            "           1       0.83      0.69      0.76       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.90      0.84      0.87      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8379077482758494 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     12283\n",
            "           1       0.81      0.66      0.73      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.82      0.85     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8202932961046822 \n",
            "\n",
            "Epoch: 40, Loss:0.1487 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     24915\n",
            "           1       0.83      0.71      0.77      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.90      0.85      0.87     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8488354850937632 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      4821\n",
            "           1       0.82      0.70      0.76       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.90      0.84      0.87      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8432026305033821 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97     12283\n",
            "           1       0.81      0.67      0.73      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.83      0.85     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.827611643056191 \n",
            "\n",
            "Epoch: 41, Loss:0.1485 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     24915\n",
            "           1       0.83      0.73      0.77      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.90      0.86      0.88     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8557411867014517 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      4821\n",
            "           1       0.82      0.72      0.77       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.90      0.85      0.87      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8507810380865763 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97     12283\n",
            "           1       0.80      0.69      0.74      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.83      0.86     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8339310337777722 \n",
            "\n",
            "Epoch: 42, Loss:0.1471 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     24915\n",
            "           1       0.82      0.74      0.78      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.90      0.86      0.88     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8594138961357504 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      4821\n",
            "           1       0.81      0.72      0.77       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.89      0.85      0.87      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8531173404324522 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97     12283\n",
            "           1       0.80      0.69      0.74      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.88      0.84      0.86     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8371794745420257 \n",
            "\n",
            "Epoch: 43, Loss:0.1460 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     24915\n",
            "           1       0.82      0.74      0.78      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.90      0.86      0.88     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8614710014047762 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      4821\n",
            "           1       0.81      0.73      0.77       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.89      0.86      0.87      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8559722073914788 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97     12283\n",
            "           1       0.80      0.70      0.74      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.88      0.84      0.86     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8387556561884418 \n",
            "\n",
            "Epoch: 44, Loss:0.1443 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     24915\n",
            "           1       0.83      0.74      0.78      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.90      0.86      0.88     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8621624634869668 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      4821\n",
            "           1       0.81      0.73      0.77       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.89      0.86      0.87      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8570621136079946 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97     12283\n",
            "           1       0.80      0.70      0.75      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.88      0.84      0.86     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8389184828594506 \n",
            "\n",
            "Epoch: 45, Loss:0.1433 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     24915\n",
            "           1       0.84      0.74      0.78      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.90      0.86      0.88     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8615375610408723 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      4821\n",
            "           1       0.82      0.73      0.77       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.89      0.85      0.87      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8544146724942284 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97     12283\n",
            "           1       0.81      0.70      0.75      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.84      0.86     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8392848428692201 \n",
            "\n",
            "Epoch: 46, Loss:0.1413 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     24915\n",
            "           1       0.84      0.74      0.79      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.86      0.88     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.86082324347225 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      4821\n",
            "           1       0.83      0.72      0.77       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.90      0.85      0.88      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.854258182581384 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97     12283\n",
            "           1       0.81      0.70      0.75      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.84      0.86     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8399027749534612 \n",
            "\n",
            "Epoch: 47, Loss:0.1414 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     24915\n",
            "           1       0.85      0.74      0.79      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.86      0.88     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8605687113965259 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      4821\n",
            "           1       0.84      0.72      0.78       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.91      0.85      0.88      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8536868409780191 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     12283\n",
            "           1       0.82      0.69      0.75      1338\n",
            "\n",
            "    accuracy                           0.95     13621\n",
            "   macro avg       0.89      0.84      0.86     13621\n",
            "weighted avg       0.95      0.95      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8388557799878232 \n",
            "\n",
            "Epoch: 48, Loss:0.1412 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     24915\n",
            "           1       0.85      0.73      0.79      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.86      0.88     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8603187504180883 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      4821\n",
            "           1       0.84      0.72      0.78       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.91      0.85      0.88      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8530117864520238 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     12283\n",
            "           1       0.82      0.70      0.75      1338\n",
            "\n",
            "    accuracy                           0.96     13621\n",
            "   macro avg       0.90      0.84      0.86     13621\n",
            "weighted avg       0.95      0.96      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8394330054043122 \n",
            "\n",
            "Epoch: 49, Loss:0.1391 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     24915\n",
            "           1       0.85      0.74      0.79      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.86      0.89     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8623156509911476 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      4821\n",
            "           1       0.84      0.72      0.78       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.91      0.85      0.88      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8547767471945347 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     12283\n",
            "           1       0.82      0.70      0.75      1338\n",
            "\n",
            "    accuracy                           0.96     13621\n",
            "   macro avg       0.89      0.84      0.86     13621\n",
            "weighted avg       0.95      0.96      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8403505482987351 \n",
            "\n",
            "Epoch: 50, Loss:0.1385 Train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98     24915\n",
            "           1       0.85      0.74      0.79      2700\n",
            "\n",
            "    accuracy                           0.96     27615\n",
            "   macro avg       0.91      0.86      0.89     27615\n",
            "weighted avg       0.96      0.96      0.96     27615\n",
            "\n",
            " Train_auc_roc: 0.8648279706557853 \n",
            "\n",
            "Valid:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      4821\n",
            "           1       0.84      0.73      0.78       507\n",
            "\n",
            "    accuracy                           0.96      5328\n",
            "   macro avg       0.91      0.86      0.88      5328\n",
            "weighted avg       0.96      0.96      0.96      5328\n",
            "\n",
            " Val_auc_roc: 0.8556592275657903 \n",
            "\n",
            "Test:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     12283\n",
            "           1       0.82      0.70      0.76      1338\n",
            "\n",
            "    accuracy                           0.96     13621\n",
            "   macro avg       0.89      0.84      0.87     13621\n",
            "weighted avg       0.95      0.96      0.95     13621\n",
            "\n",
            " Test_auc_roc: 0.8440060557405102 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time group split - inductive"
      ],
      "metadata": {
        "id": "tFWANmeX7U38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(data2['train'].x.shape[1], args['hidden_dim'],\n",
        "            2, args['num_layers'], args['dropout']).to(device)"
      ],
      "metadata": {
        "id": "oYtuNTCf7FOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = torch.nn.NLLLoss(weight=args['label_weight'])\n",
        "\n",
        "best_model = None\n",
        "best_valid_auc = 0\n",
        "best_result = None\n",
        "losses = []\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "    # train with random split\n",
        "    loss = train_ind(model, data2['train'], optimizer, loss_fn)\n",
        "    losses.append(loss)\n",
        "    result = test_ind(model, data2)\n",
        "    train_acc, val_acc, test_acc, train_auc, val_auc, test_auc = result \n",
        "    if val_auc > best_valid_auc:\n",
        "        best_valid_auc = val_auc\n",
        "        best_model = copy.deepcopy(model)\n",
        "        best_result = [train_acc, val_acc, test_acc, train_auc, val_auc, test_auc]\n",
        "\n",
        "    print('Epoch: {:02},'.format(epoch),\n",
        "          'Loss:{:.4f}'.format(loss),\n",
        "          'Train:\\n{}\\n'.format(train_acc),\n",
        "          'Train_auc_roc: {}'.format(train_auc),\n",
        "          '\\n\\n'\n",
        "          'Valid:\\n{}\\n'.format(val_acc),\n",
        "          'Val_auc_roc: {}'.format(val_auc),\n",
        "          '\\n\\n'\n",
        "          'Test:\\n{}\\n'.format(test_acc),\n",
        "          'Test_auc_roc: {}'.format(test_auc),\n",
        "          '\\n'\n",
        "          )\n"
      ],
      "metadata": {
        "id": "p2BchGcd7HHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temporal step split - inductive"
      ],
      "metadata": {
        "id": "tpPWZjqC9wVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(data['train'][0].x.shape[1], args['hidden_dim'],\n",
        "            2, args['num_layers'], args['dropout']).to(device)"
      ],
      "metadata": {
        "id": "GJTI1G4Z9vpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.reset_parameters()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
        "loss_fn = torch.nn.NLLLoss(weight=args['label_weight'])\n",
        "\n",
        "best_model = None\n",
        "best_valid_auc = 0\n",
        "best_result = None\n",
        "losses = []\n",
        "\n",
        "for epoch in range(1, 1 + args[\"epochs\"]):\n",
        "    # train with random split\n",
        "    loss = train_ind_time_step(model, data['train'], optimizer, loss_fn)\n",
        "    losses.append(loss)\n",
        "    result = test_ind_time_step(model, data)\n",
        "    train_acc, val_acc, test_acc, train_auc, val_auc, test_auc = result \n",
        "    if val_auc > best_valid_auc:\n",
        "        best_valid_auc = val_auc\n",
        "        best_model = copy.deepcopy(model)\n",
        "        best_result = [train_acc, val_acc, test_acc, train_auc, val_auc, test_auc]\n",
        "\n",
        "    print('Epoch: {:02},'.format(epoch),\n",
        "          'Loss:{:.4f}'.format(loss),\n",
        "          'Train:\\n{}\\n'.format(train_acc),\n",
        "          'Train_auc_roc: {}'.format(train_auc),\n",
        "          '\\n\\n'\n",
        "          'Valid:\\n{}\\n'.format(val_acc),\n",
        "          'Val_auc_roc: {}'.format(val_auc),\n",
        "          '\\n\\n'\n",
        "          'Test:\\n{}\\n'.format(test_acc),\n",
        "          'Test_auc_roc: {}'.format(test_auc),\n",
        "          '\\n'\n",
        "          )\n"
      ],
      "metadata": {
        "id": "FD7U-6tA96sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKUrtouq_iNS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}